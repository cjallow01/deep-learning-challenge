{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjallow01/deep-learning-challenge/blob/main/AlphabetSoupCharity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDNTCzYW2csr"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALXnUTTC2csv",
        "outputId": "d2e9e4ec-e949-4f95-a1d1-7cbbcec418a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        " !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "071JlYEG2csw"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd \n",
        "# from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "3n1iixvPXHlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "application_df = pd.read_csv(\"charity_data.csv\")\n",
        "application_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "WZiwRfuZE5wr",
        "outputId": "f5a8ea56-0d26-44ec-d244-4b9c2b6aafcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-652daf2f-d6d7-4ca4-a541-5e9f3c290c93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-652daf2f-d6d7-4ca4-a541-5e9f3c290c93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-652daf2f-d6d7-4ca4-a541-5e9f3c290c93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-652daf2f-d6d7-4ca4-a541-5e9f3c290c93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "rSydKTXG2csy",
        "outputId": "0ed56269-c492-4811-e4ba-9029305bc51d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
              "0                  T10       Independent          C1000    ProductDev   \n",
              "1                   T3       Independent          C2000  Preservation   \n",
              "2                   T5  CompanySponsored          C3000    ProductDev   \n",
              "3                   T3  CompanySponsored          C2000  Preservation   \n",
              "4                   T3       Independent          C1000     Heathcare   \n",
              "...                ...               ...            ...           ...   \n",
              "34294               T4       Independent          C1000    ProductDev   \n",
              "34295               T4  CompanySponsored          C3000    ProductDev   \n",
              "34296               T3  CompanySponsored          C2000  Preservation   \n",
              "34297               T5       Independent          C3000    ProductDev   \n",
              "34298               T3       Independent          C1000  Preservation   \n",
              "\n",
              "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
              "0       Association       1              0                      N      5000   \n",
              "1      Co-operative       1         1-9999                      N    108590   \n",
              "2       Association       1              0                      N      5000   \n",
              "3             Trust       1    10000-24999                      N      6692   \n",
              "4             Trust       1  100000-499999                      N    142590   \n",
              "...             ...     ...            ...                    ...       ...   \n",
              "34294   Association       1              0                      N      5000   \n",
              "34295   Association       1              0                      N      5000   \n",
              "34296   Association       1              0                      N      5000   \n",
              "34297   Association       1              0                      N      5000   \n",
              "34298  Co-operative       1          1M-5M                      N  36500179   \n",
              "\n",
              "       IS_SUCCESSFUL  \n",
              "0                  1  \n",
              "1                  1  \n",
              "2                  0  \n",
              "3                  1  \n",
              "4                  1  \n",
              "...              ...  \n",
              "34294              0  \n",
              "34295              0  \n",
              "34296              0  \n",
              "34297              1  \n",
              "34298              0  \n",
              "\n",
              "[34299 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e39470a-404b-4b5f-a02a-6deb1b89dc4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>T4</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>T4</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>T5</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1M-5M</td>\n",
              "      <td>N</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e39470a-404b-4b5f-a02a-6deb1b89dc4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e39470a-404b-4b5f-a02a-6deb1b89dc4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e39470a-404b-4b5f-a02a-6deb1b89dc4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "df_charity = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "df_charity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eqskV0q2csy",
        "outputId": "5b6be0b5-6b81-4c6a-f39b-64fea46fb5fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "df_charity.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfBPlskq2csz",
        "outputId": "e9d0fb80-21b2-483f-fa30-eba14bada5fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_counts = df_charity['APPLICATION_TYPE'].value_counts()\n",
        "application_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RusDiaH2csz",
        "outputId": "6ede9d30-52fe-4a6c-9843-c8aa8874f3a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = list(application_counts[application_counts<400].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bEq18o-c2csz"
      },
      "outputs": [],
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ1oRUHV2csz",
        "outputId": "c2022886-c8e0-421a-9611-641580f19525"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "application_df['CLASSIFICATION'].value_counts().loc[lambda x : x >1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6i5Bw-T2cs0",
        "outputId": "ccf5e725-2493-4058-e9e8-fc5fdb61749c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "Other     2261\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = list(classification_counts[classification_counts<800].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "TdZOTTBQ2cs0",
        "outputId": "0df124e2-1030-4129-c4ad-6648183e81c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN  STATUS  ASK_AMT  IS_SUCCESSFUL  \\\n",
              "0  10520599       1     5000              1   \n",
              "1  10531628       1   108590              1   \n",
              "2  10547893       1     5000              0   \n",
              "3  10553066       1     6692              1   \n",
              "4  10556103       1   142590              1   \n",
              "\n",
              "   NAME_1 DAY RANCH RESCUE AND RURAL OKLAHOMA ANIMAL RESOURCE INC  \\\n",
              "0                                                  0                \n",
              "1                                                  0                \n",
              "2                                                  0                \n",
              "3                                                  0                \n",
              "4                                                  0                \n",
              "\n",
              "   NAME_100 BLACK MEN OF AMERICA  NAME_100 BLACK MEN OF MEMPHIS INC  \\\n",
              "0                              0                                  0   \n",
              "1                              0                                  0   \n",
              "2                              0                                  0   \n",
              "3                              0                                  0   \n",
              "4                              0                                  0   \n",
              "\n",
              "   NAME_100 BLACK MEN OF WEST GEORGIA INC  NAME_1150 WEBSTER STREET INC  \\\n",
              "0                                       0                             0   \n",
              "1                                       0                             0   \n",
              "2                                       0                             0   \n",
              "3                                       0                             0   \n",
              "4                                       0                             0   \n",
              "\n",
              "   NAME_116TH CAVALRY REGIMENT CHAPTER OF THE US CAVALRY & ARMOR ASSOCIATION  \\\n",
              "0                                                  0                           \n",
              "1                                                  0                           \n",
              "2                                                  0                           \n",
              "3                                                  0                           \n",
              "4                                                  0                           \n",
              "\n",
              "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0  ...                  0                       0                         0   \n",
              "1  ...                  1                       0                         0   \n",
              "2  ...                  0                       0                         0   \n",
              "3  ...                  0                       1                         0   \n",
              "4  ...                  0                       0                         1   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0                   0                 0                       0   \n",
              "1                   0                 0                       0   \n",
              "2                   0                 0                       0   \n",
              "3                   0                 0                       0   \n",
              "4                   0                 0                       0   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0                0                  0                         1   \n",
              "1                0                  0                         1   \n",
              "2                0                  0                         1   \n",
              "3                0                  0                         1   \n",
              "4                0                  0                         1   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                         0  \n",
              "1                         0  \n",
              "2                         0  \n",
              "3                         0  \n",
              "4                         0  \n",
              "\n",
              "[5 rows x 19613 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09aabc43-cd04-41e9-9431-7cd405fcbb64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>NAME_1 DAY RANCH RESCUE AND RURAL OKLAHOMA ANIMAL RESOURCE INC</th>\n",
              "      <th>NAME_100 BLACK MEN OF AMERICA</th>\n",
              "      <th>NAME_100 BLACK MEN OF MEMPHIS INC</th>\n",
              "      <th>NAME_100 BLACK MEN OF WEST GEORGIA INC</th>\n",
              "      <th>NAME_1150 WEBSTER STREET INC</th>\n",
              "      <th>NAME_116TH CAVALRY REGIMENT CHAPTER OF THE US CAVALRY &amp; ARMOR ASSOCIATION</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 19613 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09aabc43-cd04-41e9-9431-7cd405fcbb64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09aabc43-cd04-41e9-9431-7cd405fcbb64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09aabc43-cd04-41e9-9431-7cd405fcbb64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_dummies = pd.get_dummies(application_df)\n",
        "application_dummies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NZngJIxX2cs3"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "# X = application_dummies.drop('IS_SUCCESSFUL', axis=1).values\n",
        "# y = application_dummies['IS_SUCCESSFUL'].values\n",
        "\n",
        "y = application_dummies[\"IS_SUCCESSFUL\"]\n",
        "X = application_dummies.drop([\"IS_SUCCESSFUL\"],axis=1)\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AaxUa_z42cs3"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTm35L862cs3"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1umTJIQ82cs3",
        "outputId": "7120d8b9-2610-4ef4-efce-a0b991b8584d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 15)                294195    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 25)                400       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 294,621\n",
            "Trainable params: 294,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 15\n",
        "hidden_nodes_layer2 = 25\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4_BWkfWK2cs4"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aME416a52cs4",
        "outputId": "bcbf830d-eb99-4474-89b6-f311bda00502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 6s 6ms/step - loss: 0.4923 - accuracy: 0.7645\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.2524 - accuracy: 0.8919\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.1268 - accuracy: 0.9495\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.1021 - accuracy: 0.9589\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0963 - accuracy: 0.9614\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0935 - accuracy: 0.9621\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0924 - accuracy: 0.9626\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0911 - accuracy: 0.9624\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0898 - accuracy: 0.9629\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0890 - accuracy: 0.9631\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0885 - accuracy: 0.9636\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0883 - accuracy: 0.9638\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0875 - accuracy: 0.9638\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0870 - accuracy: 0.9637\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0867 - accuracy: 0.9640\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0861 - accuracy: 0.9648\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0858 - accuracy: 0.9640\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0854 - accuracy: 0.9651\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0852 - accuracy: 0.9645\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0854 - accuracy: 0.9640\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0845 - accuracy: 0.9645\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0836 - accuracy: 0.9654\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0844 - accuracy: 0.9654\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0836 - accuracy: 0.9655\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0833 - accuracy: 0.9654\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0827 - accuracy: 0.9663\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0829 - accuracy: 0.9662\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0828 - accuracy: 0.9657\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0823 - accuracy: 0.9661\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0818 - accuracy: 0.9667\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0821 - accuracy: 0.9665\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0810 - accuracy: 0.9669\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0815 - accuracy: 0.9663\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0812 - accuracy: 0.9664\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0807 - accuracy: 0.9669\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0806 - accuracy: 0.9669\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 7s 9ms/step - loss: 0.0803 - accuracy: 0.9673\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0803 - accuracy: 0.9665\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0803 - accuracy: 0.9668\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0797 - accuracy: 0.9673\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0791 - accuracy: 0.9672\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0795 - accuracy: 0.9670\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0791 - accuracy: 0.9672\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0792 - accuracy: 0.9674\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0790 - accuracy: 0.9676\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0792 - accuracy: 0.9677\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0785 - accuracy: 0.9680\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0783 - accuracy: 0.9677\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0780 - accuracy: 0.9680\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0775 - accuracy: 0.9673\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0775 - accuracy: 0.9680\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0776 - accuracy: 0.9681\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0769 - accuracy: 0.9686\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0771 - accuracy: 0.9686\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0772 - accuracy: 0.9686\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0765 - accuracy: 0.9686\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0766 - accuracy: 0.9679\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0770 - accuracy: 0.9686\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0764 - accuracy: 0.9684\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0761 - accuracy: 0.9682\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0763 - accuracy: 0.9684\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0761 - accuracy: 0.9689\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0757 - accuracy: 0.9687\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0752 - accuracy: 0.9689\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0755 - accuracy: 0.9689\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0757 - accuracy: 0.9686\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0752 - accuracy: 0.9689\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0749 - accuracy: 0.9689\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0755 - accuracy: 0.9687\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0753 - accuracy: 0.9687\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0749 - accuracy: 0.9686\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0745 - accuracy: 0.9689\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0750 - accuracy: 0.9680\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0750 - accuracy: 0.9689\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0745 - accuracy: 0.9694\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0744 - accuracy: 0.9694\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0742 - accuracy: 0.9691\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0740 - accuracy: 0.9691\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0740 - accuracy: 0.9700\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0739 - accuracy: 0.9689\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0742 - accuracy: 0.9691\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0740 - accuracy: 0.9690\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0735 - accuracy: 0.9694\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0735 - accuracy: 0.9696\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0735 - accuracy: 0.9696\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0732 - accuracy: 0.9694\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0732 - accuracy: 0.9695\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0738 - accuracy: 0.9690\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0732 - accuracy: 0.9689\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0729 - accuracy: 0.9696\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0729 - accuracy: 0.9696\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0733 - accuracy: 0.9692\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0731 - accuracy: 0.9685\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0729 - accuracy: 0.9698\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0730 - accuracy: 0.9692\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0728 - accuracy: 0.9701\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0728 - accuracy: 0.9696\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0724 - accuracy: 0.9695\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0731 - accuracy: 0.9696\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0733 - accuracy: 0.9691\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB3Fx2fF2cs5",
        "outputId": "76f8b32c-5301-47ce-b89c-3c0deca4d119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.6765 - accuracy: 0.7420 - 939ms/epoch - 4ms/step\n",
            "Loss: 0.6765239834785461, Accuracy: 0.7420408129692078\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Gi5aTXmK2cs5",
        "outputId": "f0437400-a005-4ae6-e372-42cdfe89594f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plotting the accuracy\n",
        "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
        "history_df.plot(y = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "B0x-R3gp2cs6"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('Models/AlphabetSoupCharity1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJHCfekM2cs6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Attempt #1\n",
        "# APPLICATION_TYPE cutoff = 500\n",
        "# CLASSIFICATION cutoff = 800\n",
        "# layer1 = 15 : activation function = relu\n",
        "# layer2 = 25 : activation function = relu\n",
        "\n",
        "# Loss: 0.5536191259042167, Accuracy: 0.727580189704895\n",
        "\n",
        "# A loss value of 55 indicates that the model can be further optimized.\n",
        "# The accuracy percent shows that 72% of the model's predicted values align with the true values in the original dataset.\n",
        "\n",
        "# I need to make some changes in order to get to 75% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92Idy8jL2cs7",
        "outputId": "d640425a-055d-47ac-e796-51bef2cc0482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 15)                294195    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 25)                400       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 35)                910       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 295,541\n",
            "Trainable params: 295,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 15\n",
        "hidden_nodes_layer2 = 25\n",
        "hidden_nodes_layer3 = 35\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GTuxj2iX2cs7"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FREh9dKE2cs7"
      },
      "outputs": [],
      "source": [
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rJlNBF22cs7",
        "outputId": "f78ff456-af54-45ce-edb4-934e36bef368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 7s 7ms/step - loss: 0.4963 - accuracy: 0.7633\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.2462 - accuracy: 0.8959\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.1125 - accuracy: 0.9563\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0982 - accuracy: 0.9605\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0942 - accuracy: 0.9614\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0924 - accuracy: 0.9617\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0909 - accuracy: 0.9623\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0902 - accuracy: 0.9625\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0894 - accuracy: 0.9624\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0893 - accuracy: 0.9626\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0899 - accuracy: 0.9622\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0884 - accuracy: 0.9626\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0870 - accuracy: 0.9632\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0873 - accuracy: 0.9637\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.0866 - accuracy: 0.9637\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0862 - accuracy: 0.9634\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0858 - accuracy: 0.9638\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0854 - accuracy: 0.9642\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0852 - accuracy: 0.9638\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0851 - accuracy: 0.9640\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0848 - accuracy: 0.9639\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0840 - accuracy: 0.9643\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0841 - accuracy: 0.9646\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0841 - accuracy: 0.9649\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0837 - accuracy: 0.9644\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0834 - accuracy: 0.9645\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0830 - accuracy: 0.9652\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0832 - accuracy: 0.9649\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0827 - accuracy: 0.9648\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0825 - accuracy: 0.9646\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0820 - accuracy: 0.9655\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0820 - accuracy: 0.9652\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0819 - accuracy: 0.9650\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0814 - accuracy: 0.9657\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0817 - accuracy: 0.9654\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0816 - accuracy: 0.9657\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0813 - accuracy: 0.9665\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0813 - accuracy: 0.9666\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0811 - accuracy: 0.9665\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0805 - accuracy: 0.9661\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0804 - accuracy: 0.9666\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0804 - accuracy: 0.9666\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0800 - accuracy: 0.9666\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0797 - accuracy: 0.9668\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0800 - accuracy: 0.9663\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0795 - accuracy: 0.9667\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0793 - accuracy: 0.9674\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0790 - accuracy: 0.9670\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0792 - accuracy: 0.9674\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0796 - accuracy: 0.9670\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0792 - accuracy: 0.9676\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0785 - accuracy: 0.9676\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0782 - accuracy: 0.9681\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0782 - accuracy: 0.9675\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0788 - accuracy: 0.9674\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0781 - accuracy: 0.9677\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0781 - accuracy: 0.9676\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0783 - accuracy: 0.9681\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0778 - accuracy: 0.9676\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0775 - accuracy: 0.9678\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0778 - accuracy: 0.9679\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0776 - accuracy: 0.9676\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0778 - accuracy: 0.9673\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0773 - accuracy: 0.9680\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0772 - accuracy: 0.9680\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0772 - accuracy: 0.9680\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0770 - accuracy: 0.9676\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0773 - accuracy: 0.9680\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0768 - accuracy: 0.9684\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0773 - accuracy: 0.9686\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0761 - accuracy: 0.9689\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0768 - accuracy: 0.9683\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0764 - accuracy: 0.9680\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0759 - accuracy: 0.9689\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0758 - accuracy: 0.9684\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0767 - accuracy: 0.9687\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0762 - accuracy: 0.9681\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0754 - accuracy: 0.9691\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0762 - accuracy: 0.9680\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0761 - accuracy: 0.9682\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0758 - accuracy: 0.9690\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0783 - accuracy: 0.9681\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0753 - accuracy: 0.9693\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0747 - accuracy: 0.9690\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0752 - accuracy: 0.9682\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0757 - accuracy: 0.9690\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0756 - accuracy: 0.9687\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0752 - accuracy: 0.9689\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0753 - accuracy: 0.9686\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0751 - accuracy: 0.9691\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0751 - accuracy: 0.9691\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0753 - accuracy: 0.9689\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0759 - accuracy: 0.9692\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0756 - accuracy: 0.9687\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0752 - accuracy: 0.9684\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0748 - accuracy: 0.9691\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0748 - accuracy: 0.9693\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0750 - accuracy: 0.9690\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0750 - accuracy: 0.9691\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0748 - accuracy: 0.9689\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuRDHdYY2cs8",
        "outputId": "04f7a13b-27e2-412d-b2f9-29bbb838d28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.8111 - accuracy: 0.6844 - 1s/epoch - 4ms/step\n",
            "Loss: 0.8111224174499512, Accuracy: 0.6844314932823181\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "J-3bYKHA2cs8",
        "outputId": "cae6cd0f-81cf-4db0-8aa7-d384f71f442f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plotting the accuracy\n",
        "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
        "history_df.plot(y = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jZsC6UZX2cs8"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('Models/AlphabetSoupCharity1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvu9w8ln2cs8"
      },
      "outputs": [],
      "source": [
        "# Attempt #2 -- adding a hidden layer\n",
        "# APPLICATION_TYPE cutoff = 600\n",
        "# CLASSIFICATION cutoff = 300\n",
        "# layer1 = 15 : activation function = relu\n",
        "# layer2 = 25 : activation function = relu\n",
        "# layer3 = 35 : activation function = relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iBraYjGa2cs8"
      },
      "outputs": [],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 15\n",
        "hidden_nodes_layer2 = 25\n",
        "hidden_nodes_layer3 = 35\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6U4ONq012cs8"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6269X6r72cs8"
      },
      "outputs": [],
      "source": [
        "# y_test = np.array(y_test)\n",
        "# y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deVPYCBy2cs8",
        "outputId": "8c11160c-61e1-4aaa-9610-7cfbda46b298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "804/804 [==============================] - 7s 7ms/step - loss: 0.4827 - accuracy: 0.7704\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.2388 - accuracy: 0.9013\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.1172 - accuracy: 0.9561\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0975 - accuracy: 0.9610\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0930 - accuracy: 0.9621\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0916 - accuracy: 0.9626\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0910 - accuracy: 0.9629\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0899 - accuracy: 0.9629\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0894 - accuracy: 0.9633\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0890 - accuracy: 0.9627\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0874 - accuracy: 0.9636\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0876 - accuracy: 0.9638\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0869 - accuracy: 0.9632\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0864 - accuracy: 0.9642\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0861 - accuracy: 0.9643\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0865 - accuracy: 0.9645\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.0855 - accuracy: 0.9638\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0851 - accuracy: 0.9645\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0849 - accuracy: 0.9651\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 7s 8ms/step - loss: 0.0849 - accuracy: 0.9647\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0843 - accuracy: 0.9647\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0841 - accuracy: 0.9646\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0841 - accuracy: 0.9648\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0837 - accuracy: 0.9647\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0834 - accuracy: 0.9645\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0829 - accuracy: 0.9659\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0829 - accuracy: 0.9654\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0823 - accuracy: 0.9653\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0819 - accuracy: 0.9656\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0822 - accuracy: 0.9653\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0819 - accuracy: 0.9657\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0817 - accuracy: 0.9656\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0812 - accuracy: 0.9654\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0813 - accuracy: 0.9654\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0809 - accuracy: 0.9657\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0808 - accuracy: 0.9658\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0807 - accuracy: 0.9661\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0804 - accuracy: 0.9664\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0800 - accuracy: 0.9663\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0802 - accuracy: 0.9663\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0795 - accuracy: 0.9669\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0797 - accuracy: 0.9665\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0791 - accuracy: 0.9670\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0789 - accuracy: 0.9673\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0793 - accuracy: 0.9668\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0789 - accuracy: 0.9663\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0792 - accuracy: 0.9670\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0784 - accuracy: 0.9668\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0784 - accuracy: 0.9672\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0787 - accuracy: 0.9670\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0784 - accuracy: 0.9672\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0782 - accuracy: 0.9666\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0777 - accuracy: 0.9672\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0775 - accuracy: 0.9672\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0782 - accuracy: 0.9678\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0775 - accuracy: 0.9677\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0771 - accuracy: 0.9675\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0776 - accuracy: 0.9673\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0772 - accuracy: 0.9677\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0768 - accuracy: 0.9677\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0767 - accuracy: 0.9679\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0773 - accuracy: 0.9673\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0765 - accuracy: 0.9684\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0770 - accuracy: 0.9679\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0767 - accuracy: 0.9684\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0761 - accuracy: 0.9682\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0757 - accuracy: 0.9685\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0759 - accuracy: 0.9682\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0757 - accuracy: 0.9682\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0759 - accuracy: 0.9679\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0758 - accuracy: 0.9684\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0749 - accuracy: 0.9687\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0755 - accuracy: 0.9687\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0751 - accuracy: 0.9680\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0755 - accuracy: 0.9680\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0748 - accuracy: 0.9686\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0747 - accuracy: 0.9688\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0748 - accuracy: 0.9687\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0747 - accuracy: 0.9687\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0746 - accuracy: 0.9691\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0744 - accuracy: 0.9692\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0746 - accuracy: 0.9693\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0747 - accuracy: 0.9687\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0738 - accuracy: 0.9688\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0741 - accuracy: 0.9688\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0738 - accuracy: 0.9695\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0740 - accuracy: 0.9689\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0738 - accuracy: 0.9697\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0744 - accuracy: 0.9686\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0749 - accuracy: 0.9689\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0733 - accuracy: 0.9694\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0741 - accuracy: 0.9690\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.0732 - accuracy: 0.9693\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0733 - accuracy: 0.9694\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0735 - accuracy: 0.9698\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0731 - accuracy: 0.9702\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0741 - accuracy: 0.9694\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0738 - accuracy: 0.9694\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 6s 8ms/step - loss: 0.0730 - accuracy: 0.9697\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.0734 - accuracy: 0.9698\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q3daJrS2cs8",
        "outputId": "78338fc3-d25a-4308-9375-c6f75a7fb0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 1s - loss: 0.6973 - accuracy: 0.7255 - 929ms/epoch - 3ms/step\n",
            "Loss: 0.6973182559013367, Accuracy: 0.7254810333251953\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "7RJg6As42cs9",
        "outputId": "2a3159e9-444d-4584-b9d1-7222609ca4f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plotting the accuracy\n",
        "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
        "history_df.plot(y = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LCzU1LkS2cs9"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save('Models/AlphabetSoupCharity2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZYkZTv32cs9"
      },
      "outputs": [],
      "source": [
        "# Attempt #2 -- adding a hidden layer\n",
        "# APPLICATION_TYPE cutoff = 600\n",
        "# CLASSIFICATION cutoff = 300\n",
        "# layer1 = 15 : activation function = relu\n",
        "# layer2 = 25 : activation function = relu\n",
        "# layer3 = 35 : activation function = relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx5pN47L2cs9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "a6897b9bc8f2b8346b5014e6a604b0c2817e17d20fd38d47a3193bb4a35a028d"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}